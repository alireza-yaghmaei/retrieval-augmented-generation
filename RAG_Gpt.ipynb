{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKwUjmi38R7W"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMId70LBP8A-"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.2.5 langchain-openai==0.1.9 langchain-community==0.2.5 chromadb==0.5.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnX65M8h85ZY"
      },
      "source": [
        "# RAG using data.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdihBzKK9JmT"
      },
      "source": [
        "## import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6YWB6lU-9IBk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#import sys\n",
        "import getpass\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "import chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E28iL9CN7NA"
      },
      "source": [
        "## OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNBKhXD1N6es",
        "outputId": "5beeebea-5ffc-44c6-a38c-dfa923ed3638"
      },
      "outputs": [],
      "source": [
        "api_key = getpass.getpass(\"Enter your OPENAI_API_KEY:\\n\\n\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg5wFS4MN1Dx"
      },
      "source": [
        "## Prompt and Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uwovZyrUNzfH"
      },
      "outputs": [],
      "source": [
        "template1=  \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "      If the context is not relevant, please answer the question by using your own knowledge about the topic. just before answering write \"BAASED ON MY OWN KNOWLEDGE: \"\n",
        "      you can also give a combined answer but remember to tell me which is which.\n",
        "\n",
        "      {context}\n",
        "\n",
        "      Question: {question}\n",
        "\"\"\"\n",
        "template2=  \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "      If the context is not relevant, dont try to use your own knowledge and simply say i don't know.\n",
        "\n",
        "      {context}\n",
        "\n",
        "      Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = template1\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "chain_type_kwargs = {\"prompt\": PROMPT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7k_dlhd9hFq"
      },
      "source": [
        "## Show Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qA7j7Ij9f6q",
        "outputId": "78fab7d0-f56c-4a53-87c6-0ec2356cbe68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "im going to doctor on October 15 2023.\n",
            "im going to specialist doctor on the next week.\n",
            "today is 10/4/2023.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('data.txt', 'r') as file:\n",
        "    file_content = file.read()\n",
        "print(file_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcYMKCjGOQuA"
      },
      "source": [
        "## Generate Retrieval Augment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "opPNq4GKGbFB"
      },
      "outputs": [],
      "source": [
        "# Load and split document\n",
        "loader = TextLoader(\"data.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Embedding\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create a vecorstore using chroma\n",
        "db = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "# Define a retriever\n",
        "retriever = db.as_retriever(search_type=\"similarity\")   # search_type = similarity / mmr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ddNaXJGhiG"
      },
      "source": [
        "## Run OpenAI Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "us5n9orS9-87"
      },
      "outputs": [],
      "source": [
        "# Define OpenAI model with proper arguments\n",
        "llm_openai =  ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    temperature=0\n",
        "    )\n",
        "\n",
        "# Define Retriveal Q/A\n",
        "qa_openai = RetrievalQA.from_chain_type(\n",
        "    llm=llm_openai,\n",
        "    chain_type=\"stuff\",                     # chain_type = ['stuff', 'map_reduce', 'refine', 'map_rerank']\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs=chain_type_kwargs,\n",
        "    verbose=True,\n",
        "    return_source_documents=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdiiRjvmC5Rk"
      },
      "source": [
        "## enter and run query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gru8b0ziUfLe",
        "outputId": "f65005d4-295b-4777-9662-4aabb946b7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "question = \"when is my doctor appointment?\"\n",
        "result = qa_openai.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlt4ylmbU-oB",
        "outputId": "66026ff4-99f2-4ab4-b847-73eda9467d69"
      },
      "outputs": [],
      "source": [
        "print(\"Question:\")\n",
        "print(result['query'])\n",
        "\n",
        "print(\"Answer:\")\n",
        "print(result['result'])\n",
        "\n",
        "sources = result['source_documents']\n",
        "print(\"\\nSources:\\n\")\n",
        "for source in sources:\n",
        "  print(source.page_content)\n",
        "  print(source.metadata)\n",
        "  print(\"\\n\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
